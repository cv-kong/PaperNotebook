# 摘要

红外与可见光图像融合结合了红外图像的热目标信息和可见光图像的纹理细节，显著提升了场景感知能力。然而，红外和RGB传感器优缺点各异。现有方法往往仅考虑单一传感器，或简单叠加多传感器信息，忽略了不同模态在不同环境下的重要性变化，导致关键信息丢失或冗余。针对上述问题，本文提出了一种基于EMMA框架的改进方法：通过注意力分支分别学习红外与可见光图像的动态权重，实现两种模态特征的差异化贡献；设计融合注意力的双分支特征解耦模块，深度融合权重学习与多模态特征提取；引入轻量级高效主干网络替换传统Unet，解决输入尺度不一致问题并强化特征提取能力。实验结果表明，该方法在红外-可见光图像融合任务中取得了优异的主观视觉质量和客观评价指标，有效提升了复杂场景下的融合性能。

# Introduction

## 研究背景与意义
红外图像的优势：热辐射感知、穿透能力，但是空间分辨率较低，热扩散效应导致边缘模糊
可见光图像的优势：高分辨率、纹理细节丰富，但是易受光照变化影响
互补性需求：单一传感器存在信息缺失，两者融合能达成互补
常规融合方法针对两者图像质量满足要求的条件下work，但是在极端光照条件下融合学习容易失真，模型学习效果失效

红外与可见光图像融合技术通过整合两种模态的互补信息来提升场景感知能力，在安防监控、自动驾驶和夜视等领域具有重要应用价值。然而，现有方法仍面临若干关键挑战：

## 1.1 现存问题

总述：当前技术存在三大瓶颈
分述：
### (1) 可见光图像问题
可见光图像常因光照条件变化导致欠曝光或过曝光区域的细节丢失。虽然现有融合算法能改善整体对比度，但在极端光照条件下仍难以获取有效效果。我们设计了自适应增强模块来解决这一问题，增强低光照下的细节表现。提高融合图像质量。

### (2) 特征表达不均衡问题
现有融合方法通常对红外（I）与可见光（V）图像采用统一特征提取模型。忽略了二者的特性差异。

### (3) 传统融合框架的局限性
现有深度学习方法多基于U-Net或CNN主干网络，这类结构在处理多尺度输入时效率不足且缺乏轻量化特性。

## 1.2 解决方案

<font color="green"> 1、 EMMA算法训练本质是什么? </font>
<font color="green"> 2、HVI算法训练本质是什么? </font>
<font color="green"> 3、怎么将HVI融合到EMMA中? </font>

### 非对称伪感知模块

- 显著提升融合鲁棒性
  提出**双分支处理策略two-stage fusion approach**：

- **可见光图像**分支：采用**增强特征提取**以恢复光照抑制的细节
  - 可见光分支：专注纹理细节（如边缘、色彩）HVI

    - 选用HVI颜色空间增强、提升RGB图像低光照下的色彩和细节表现
- **红外图像**分支：采用**简化特征提取**，在保留热目标的同时减少冗余

  - 红外分支：聚焦于热辐射特征（如高温目标、热轮廓）
    - 使用浅层网络（3层CNN）提取全局热分布；轻量级、单层、高效

### 改进架构，混合注意力融合
在**EMMA框架下引入轻量级高效主干网络**取代传统U-Net结构。这一改进：

- 显著增强了判别性特征提取能力

设计**混合注意力机制**：
- 结合通道注意力与空间注意力
- 动态强化关键特征（如红外热目标与可见光边缘）

- 共享特征空间投影

  - 通过对抗训练约束，使两类特征映射到统一潜在空间

  - 损失函数：
  $$ \mathcal{L}_{adv} = \mathbb{E}[\log D(F_{IR})] + \mathbb{E}[\log(1-D(F_{RGB}))] $$
  

- 跨模态门控注意力（Cross-modal Gated Attention
   - 动态特征加权
     - 通过通道注意力（SE模块）计算模态间权重：
    $$ \alpha_c = \sigma(W_2 ReLU(W_1[F_{IR}||F_{RGB}])) $$
     - 空间注意力补充：
   ```python
        spatial_attn = Conv2d(concat(IR_feat, RGB_feat), kernel=7x7)
        output = spatial_attn * IR_feat + (1-spatial_attn) * RGB_feat 
   ```

## 1.3 主要贡献
1. 基于EMMA框架的轻量级主干网络，实现高效多尺度特征提取
2. 面向I/V图像差异化处理的双分支伪感知模块
3. 增强关键特征表达的混合注意力融合模块

## 1.4 实验结果
实验结果表明，该方法在：
- 主观视觉质量
- 客观评价指标（如EN、SSIM）

均优于现有算法，有效提升了复杂场景下的融合性能。

# METHODOLOGY
- 介绍红外可见光图像融合的重要性，以及目前存在的问题
- 介绍EMMA框架，以及其存在的问题
  - V图像是RGB图像，存在光照问题，需要增强

## 引入模型整体介绍

- 3. 优势对比

| 特性               | DNLM                          | 传统方法          |
|--------------------|-------------------------------|------------------|
| 自适应能力         | 像素级动态调整               | 全局固定参数      |
| 语义感知           | 支持区域抑制                | 无区分           |
| 计算效率           | 实时处理4K                  | 通常更快         |


- EMMA中，存在伪感知模块backbone,Unet通过特征图可视化可知，细节特征提取的不佳；选用优化后的backbone，效果更好

# UNet作为Backbone的局限性及新型Backbone设计思路

## UNet的核心缺陷

### 1. 计算效率问题
- 对称编解码结构带来大量冗余计算
- 跳跃连接导致特征图尺寸频繁变化，内存访问效率低
- 浅层特征重复传递增加显存消耗

### 2. 特征融合瓶颈
- 简单的通道拼接(concat)操作限制多尺度特征交互
- 缺乏跨尺度注意力机制
- 深层语义信息与浅层细节融合不充分

### 3. 感受野局限
- 标准卷积核难以捕获长程依赖
- 下采样策略导致空间信息不可逆损失
- 对超大尺寸对象分割效果下降

### 4. 动态适应性不足
- 固定网络结构难以适应不同模态数据
- 缺乏对病灶形状变化的鲁棒性处理

## 创新Backbone设计原则

- EMMA中Uf模块以Unet为结构，将Restormer做为基础模块；参考上述unet替换的改进结构；
https://blog.csdn.net/u012863603/article/details/142977809
改进选用C2PSA它结合了PSA(Pointwise Spatial Attention)块，用于增强特征提取和注意力机制<font color="green">yoloV11</font>
![C2PSA](images//C2PSA.png)



# 实验
  介绍实验结果，以及与其他方法的对比
- 数据集选择：DroneVehical（https://github.com/VisDrone/DroneVehicle）
该数据集是通过搭载双摄像头（可见光摄像头和热红外摄像头）的无人机，在不同场景、多种天气和光照条件下采集的。热红外摄像头（Thermal Infrared Camera）的工作波段通常属于 长波红外（LWIR，8~14 μm），这是由 常温物体的热辐射特性 和 大气透射窗口 共同决定的



  MSRS IVF dataset https://blog.csdn.net/jiexiang5396/article/details/134851286
- 对比模型选择
- 对比模型特征图可视化
- 对比模型效果表以及曲线